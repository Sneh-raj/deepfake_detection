{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlFsO4mbGz-2",
        "outputId": "d436e5df-7974-4166-fefc-b31043bf828a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "t_eO3nMOjKxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h8ic08AbbJ9",
        "outputId": "a3e4940e-c99b-44cd-c229-8a5dd462f913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil"
      ],
      "metadata": {
        "id": "Zstes_j5NHS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths to your fake and real image folders\n",
        "fake_folder = '/content/drive/MyDrive/Augm'\n",
        "real_folder = '/content/drive/MyDrive/Instagram_photos'\n",
        "\n",
        "# Create a new folder to save labeled images\n",
        "labeled_folder = '/content/drive/MyDrive/Labelled_images'\n",
        "os.makedirs(labeled_folder, exist_ok=True)\n",
        "\n",
        "# Function to label and save images\n",
        "def label_and_save_images(folder, label):\n",
        "    for filename in os.listdir(folder):\n",
        "        image_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(image_path)\n",
        "\n",
        "        # Add a label to the image (0 for fake, 1 for real)\n",
        "        labeled_img = cv2.putText(img, f'Label: {label}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Save the labeled image to the new folder\n",
        "        labeled_path = os.path.join(labeled_folder, f'label_{label}_{filename}')\n",
        "        cv2.imwrite(labeled_path, labeled_img)\n",
        "\n",
        "# Label fake images (label 0)\n",
        "label_and_save_images(fake_folder, label=0)\n",
        "\n",
        "# Label real images (label 1)\n",
        "label_and_save_images(real_folder, label=1)\n"
      ],
      "metadata": {
        "id": "5BPMRkRfjKKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i36xF4lkjKIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def label_and_save_images(input_folder, output_folder, label):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Adjust the file extensions as needed\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            output_filename = f\"label_{label}_{len(os.listdir(output_folder)) + 1}.jpg\"  # You can use any desired extension\n",
        "            output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "            image = cv2.imread(input_path)\n",
        "\n",
        "            # Resize or preprocess the image as needed\n",
        "            # image = cv2.resize(image, (width, height))\n",
        "\n",
        "            # Save the image with the new label and filename format\n",
        "            cv2.imwrite(output_path, image)\n",
        "\n",
        "# Paths to your fake and real image folders\n",
        "fake_folder_path = \"/content/drive/MyDrive/Augm\"\n",
        "real_folder_path = \"/content/drive/MyDrive/Instagram_photos\"\n",
        "\n",
        "# Output folder for combined and labeled images\n",
        "combined_folder_path = \"/content/drive/MyDrive/labelled\"\n",
        "\n",
        "# Label and save fake images\n",
        "label_and_save_images(fake_folder_path, combined_folder_path, label=0)\n",
        "\n",
        "# Label and save real images\n",
        "label_and_save_images(real_folder_path, combined_folder_path, label=1)\n"
      ],
      "metadata": {
        "id": "AEuxOBrSjKFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ESJg46-jKDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g6Rqij1FjKAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python tqdm\n"
      ],
      "metadata": {
        "id": "xfg0lJdtjJ-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66058276-0046-4c26-9831-19872752b9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "tHFq9gzFGj3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W4QcgGLWGjy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cu8BAwEOfcuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bsb_Ah7Gfcsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def save_labeled_images(src_folder, dest_folder, label):\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "\n",
        "    image_files = os.listdir(src_folder)\n",
        "    for img_file in tqdm(image_files, desc=f\"Processing {label} images\"):\n",
        "        img_path = os.path.join(src_folder, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Assuming you want to resize the images to a specific size\n",
        "        img = cv2.resize(img, (224, 224))  # Adjust the size as needed\n",
        "\n",
        "        # Save the image with the format real<1>.jpg or fake<0>.jpg\n",
        "        dest_filename = f\"{label}.jpg\"\n",
        "        dest_path = os.path.join(dest_folder, dest_filename)\n",
        "        cv2.imwrite(dest_path, img)\n",
        "\n",
        "# Assuming you have two folders, 'fake_images' and 'real_images'\n",
        "fake_images_folder = '/content/drive/MyDrive/Augm'\n",
        "real_images_folder = '/content/drive/MyDrive/Instagram_photos'\n",
        "\n",
        "# Specify the destination folder for the labeled images\n",
        "destination_folder = '/content/drive/MyDrive/new_label'\n",
        "\n",
        "# Save fake images with label 0\n",
        "save_labeled_images(fake_images_folder, destination_folder, label=0)\n",
        "\n",
        "# Save real images with label 1\n",
        "save_labeled_images(real_images_folder, destination_folder, label=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBagKaMAfcqX",
        "outputId": "772ce1c6-6f29-47bd-801c-6a328a402f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing 0 images: 100%|██████████| 2198/2198 [01:17<00:00, 28.48it/s]\n",
            "Processing 1 images: 100%|██████████| 547/547 [00:39<00:00, 14.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def label_and_save_images(input_folder, output_folder, label):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    label_prefix = \"real\" if label == 1 else \"fake\"\n",
        "    label_count = len(os.listdir(output_folder))\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".jpeg\"):  # Adjust the file extensions as needed\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            output_filename = f\"{label_prefix}{label_count}.jpg\"\n",
        "            output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "            image = cv2.imread(input_path)\n",
        "\n",
        "            # Resize or preprocess the image as needed\n",
        "            # image = cv2.resize(image, (width, height))\n",
        "\n",
        "            # Save the image with the new label and filename format\n",
        "            cv2.imwrite(output_path, image)\n",
        "            label_count += 1\n",
        "\n",
        "# Paths to your fake and real image folders\n",
        "fake_folder_path = \"/content/drive/MyDrive/fake_aug\"\n",
        "real_folder_path = \"/content/drive/MyDrive/Real_augm\"\n",
        "\n",
        "# Output folder for combined and labeled images\n",
        "combined_folder_path = \"/content/drive/MyDrive/Labelled_Images\"\n",
        "\n",
        "# Label and save fake images\n",
        "label_and_save_images(fake_folder_path, combined_folder_path, label=0)\n",
        "\n",
        "# Label and save real images\n",
        "label_and_save_images(real_folder_path, combined_folder_path, label=1)\n"
      ],
      "metadata": {
        "id": "hBz7ts4wfcnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "njc0slgofcf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def label_and_save_images(input_folder, output_folder, label, label_prefix):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    label_count = len(os.listdir(output_folder))\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Adjust the file extensions as needed\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            output_filename = f\"{label_prefix}{label_count}.jpg\"\n",
        "            output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "            image = cv2.imread(input_path)\n",
        "\n",
        "            # Resize or preprocess the image as needed\n",
        "            # image = cv2.resize(image, (width, height))\n",
        "\n",
        "            # Save the image with the new label and filename format\n",
        "            cv2.imwrite(output_path, image)\n",
        "            label_count += 1\n",
        "\n",
        "# Paths to your fake and real image folders\n",
        "fake_folder_path = \"/content/drive/MyDrive/Augm\"\n",
        "real_folder_path = \"/content/drive/MyDrive/Instagram_photos\"\n",
        "\n",
        "# Output folder for combined and labeled images\n",
        "combined_folder_path = \"/content/drive/MyDrive/labelled_images\"\n",
        "\n",
        "# Label and save fake images\n",
        "label_and_save_images(fake_folder_path, combined_folder_path, label=0, label_prefix=\"fake\")\n",
        "\n",
        "# Label and save real images\n",
        "label_and_save_images(real_folder_path, combined_folder_path, label=1, label_prefix=\"real\")\n"
      ],
      "metadata": {
        "id": "De8cjIN8fcc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K7TN8_b6-B3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def label_and_save_images(input_folder, output_folder, label, label_prefix):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    label_count = len(os.listdir(output_folder))\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".jpeg\") or filename.endswith(\".png\"):  # Adjust the file extensions as needed\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            output_filename = f\"{label_prefix}{label_count}.jpg\"\n",
        "            output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "            image = cv2.imread(input_path)\n",
        "\n",
        "            # Resize or preprocess the image as needed\n",
        "            # image = cv2.resize(image, (width, height))\n",
        "\n",
        "            # Save the image with the new label and filename format\n",
        "            cv2.imwrite(output_path, image)\n",
        "            label_count += 1\n",
        "\n",
        "# Paths to your fake and real image folders\n",
        "Real_folder_path = \"/content/drive/MyDrive/Real_augm\"\n",
        "\n",
        "# Output folder for combined and labeled images\n",
        "combined_folder_path = \"/content/drive/MyDrive/Labelled_Images\"\n",
        "\n",
        "# Label and save fake images\n",
        "label_and_save_images(Real_folder_path, combined_folder_path, label=0, label_prefix=\"Real\")\n"
      ],
      "metadata": {
        "id": "KJ3G0eCa-Bzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W6SmmBJI3lYC",
        "outputId": "eb6000b5-86a7-4101-b907-2a961050c696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9D2QYHFS9cZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "def copy_resize_and_convert_images(source_folder, destination_folder, label, target_size=(255, 255)):\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "\n",
        "    images = []\n",
        "    image_count = 0\n",
        "    for filename in os.listdir(source_folder):\n",
        "        if filename.lower().endswith(('.jpg', '.png','.jpeg')):\n",
        "            source_path = os.path.join(source_folder, filename)\n",
        "            destination_filename = f\"{label}{image_count}.jpg\"\n",
        "            destination_path = os.path.join(destination_folder, destination_filename)\n",
        "\n",
        "            # Read and resize the image\n",
        "            image = cv2.imread(source_path)\n",
        "            resized_image = cv2.resize(image, target_size)\n",
        "\n",
        "            # Save the resized image\n",
        "            cv2.imwrite(destination_path, resized_image)\n",
        "\n",
        "            # Convert to numpy array and add to the list\n",
        "            image_array = np.asarray(resized_image)\n",
        "            images.append(image_array)\n",
        "\n",
        "            image_count += 1\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "# Example usage for fake images\n",
        "fake_images_folder = \"/content/drive/MyDrive/Augm\"\n",
        "destination_folder = \"/content/drive/MyDrive/Label_images_folder\"\n",
        "fake_images = copy_resize_and_convert_images(fake_images_folder, destination_folder, label=\"fake\")\n",
        "\n",
        "# Example usage for real images\n",
        "real_images_folder = \"/content/drive/MyDrive/Instagram_photos\"\n",
        "real_images = copy_resize_and_convert_images(real_images_folder, destination_folder, label=\"real\")\n"
      ],
      "metadata": {
        "id": "y03vUaAE9cXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(destination_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIKQ9OUa9cUm",
        "outputId": "e706d93c-accf-4b7b-af9b-e23f68540e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(destination_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XbWa7s09cSB",
        "outputId": "63a4a7b7-7e47-4be5-b0dd-1da3038f4c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_images = np.concatenate((fake_images, real_images), axis=0)\n"
      ],
      "metadata": {
        "id": "ZgfJcSOMCey-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(combined_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXxME-gtDLs2",
        "outputId": "17f4b14f-7cec-4794-9e3d-7da4b08cd010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_images.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjx03dqpDPT1",
        "outputId": "b94ffbe6-2e1c-4f6c-874a-38da566ecc22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "535480875"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8p2Nyi_BDRwN",
        "outputId": "ba048244-cd63-422a-e579-35d5ef476fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-ac4a8696-e72c-449d-bd74-60b81b101b86\" class=\"ndarray_repr\"><pre>ndarray (255, 255, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-ac4a8696-e72c-449d-bd74-60b81b101b86 button').onclick = (e) => {\n",
              "        document.querySelector('#id-ac4a8696-e72c-449d-bd74-60b81b101b86').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-ac4a8696-e72c-449d-bd74-60b81b101b86 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files_list = os.listdir(\"/content/drive/MyDrive/Labelled_Images\")\n",
        "\n",
        "# Count the number of files\n",
        "num_files = len(files_list)\n"
      ],
      "metadata": {
        "id": "bta3sHd7DUTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS9n9VJPEDw_",
        "outputId": "6ae8a21f-aeb6-4390-8a7e-8bcefaac152e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(r\"/content/drive/MyDrive/Labelled_Images\") # get the path of train folder in cats_dogs_images using copypath and paste the link here\n",
        "new_base_dir = pathlib.Path(r\"/content/drive/MyDrive/Image_segregated_2\") # create a new folder, rename it and get the path using copypath and paste the link here.\n",
        "\n",
        "\n",
        "# define a function to create subsets for train, test and validation\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"fake\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "# calling the function thrice to create 3 subsets.\n",
        "make_subset(\"train\", start_index=0, end_index=1200)\n",
        "make_subset(\"validation\", start_index=1200, end_index=1700)\n",
        "make_subset(\"test\", start_index=1700, end_index=2745)"
      ],
      "metadata": {
        "id": "AVB99XLjEKB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/Labelled_Images/fake0.jpg"
      ],
      "metadata": {
        "id": "TMYBHba0EQ2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pathlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XfUDQ69EQzM",
        "outputId": "61bae5e3-0bf6-430d-f4cb-baa7ee471b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, pathlib"
      ],
      "metadata": {
        "id": "XtdofYsqEQpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "original_dir = pathlib.Path(r\"/content/drive/MyDrive/Labelled_Images\") # get the path of train folder in cats_dogs_images using copypath and paste the link here\n",
        "new_base_dir = pathlib.Path(r\"/content/drive/MyDrive/Image_segregated_2\") # create a new folder, rename it and get the path using copypath and paste the link here.\n"
      ],
      "metadata": {
        "id": "so4aZiocINVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"Real\",\"Fake\"):\n",
        "        dir = new_base_dir / subset_name\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "        fnames = [f\"{category}{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)"
      ],
      "metadata": {
        "id": "9-GAg0zUEQmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calling the function thrice to create 3 subsets.\n",
        "make_subset(\"train\", start_index=379, end_index=1379)"
      ],
      "metadata": {
        "id": "BmSkhvmGEQjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_subset(\"validation\", start_index=1000, end_index=1400)\n"
      ],
      "metadata": {
        "id": "vGu85ES4EQgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_subset(\"test\", start_index=1781, end_index=2174)"
      ],
      "metadata": {
        "id": "eMMyLvNPEQdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QfOT0GccEQaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4lnkg0wkcv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This step helps in converting all the images present in folder to same shape.\n",
        "import cv2\n",
        "import numpy as np\n",
        "labels = ['Real','fake']\n",
        "img_size = 224\n",
        "def get_data(data_dir):\n",
        "    data = []\n",
        "    for label in labels:\n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
        "                resized_arr = cv2.resize(img_arr, (224, 224)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "daBcXRumkcdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "92NPqFSCkcZz",
        "outputId": "f474c065-8ecc-4d1e-8e44-f24f361f1c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Image_segregated_2/train/Real'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-ecc76fa0b26f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/drive/MyDrive/Image_segregated_2/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/drive/MyDrive/Image_segregated_2/validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-cdefb762dad6>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mclass_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mimg_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#convert BGR to RGB format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Image_segregated_2/train/Real'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TJNSuEjNkcW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def resize_images(folder_path, output_folder, target_shape=(224, 224)):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            resized_img = cv2.resize(img, target_shape)\n",
        "\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, resized_img)\n",
        "\n",
        "# Example usage\n",
        "base_folder = \"/content/drive/MyDrive/Image_segregated_2\"\n",
        "train_folder = os.path.join(base_folder, \"train\")\n",
        "test_folder = os.path.join(base_folder, \"test\")\n",
        "val_folder = os.path.join(base_folder, \"validation\")\n",
        "\n",
        "resized_train_folder = os.path.join(base_folder, \"resized_train\")\n",
        "resized_test_folder = os.path.join(base_folder, \"resized_test\")\n",
        "resized_val_folder = os.path.join(base_folder, \"resized_validation\")\n",
        "\n",
        "resize_images(train_folder, resized_train_folder)\n",
        "resize_images(test_folder, resized_test_folder)\n",
        "resize_images(val_folder, resized_val_folder)\n"
      ],
      "metadata": {
        "id": "iLItVYo5kcUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = ('/content/drive/MyDrive/Image_segregated_2/train')\n",
        "val = ('/content/drive/MyDrive/Image_segregated_2/val')"
      ],
      "metadata": {
        "id": "fiRu0UEgkcR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tg1-91B8kcPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "for feature, label in train:\n",
        "  x_train.append(feature)\n",
        "  y_train.append(label)\n",
        "\n",
        "for feature, label in val:\n",
        "  x_val.append(feature)\n",
        "  y_val.append(label)\n",
        "\n",
        "# Normalize the data\n",
        "x_train = np.array(x_train).astype('float32') / 255\n",
        "x_val = np.array(x_val).astype('float32') / 255\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "QyiIZVgBkcNH",
        "outputId": "302305dc-f97f-4cb1-ef74-31c3f16f2890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-e29f39177b47>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_images_and_labels(folder_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Resize or preprocess the image as needed\n",
        "            # img = cv2.resize(img, (width, height))\n",
        "\n",
        "            label = int(filename.startswith(\"fake\"))  # Assuming \"fake\" corresponds to label 0, adjust accordingly\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Example usage\n",
        "train_folder = \"/content/drive/MyDrive/deep_fake_image_detection/Image_segregated_2/train\"\n",
        "X_train, y_train = load_images_and_labels(train_folder)\n",
        "\n",
        "# Now you have X_train (images) and y_train (labels) ready to use\n"
      ],
      "metadata": {
        "id": "QtBWdvGmASep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0mFQhnoASNp",
        "outputId": "db0c085e-bafc-44f3-84ae-ca51225f81f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfsvbzO5ASJ4",
        "outputId": "327b2d57-7a83-4021-8fd4-d8bc907a96ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999,)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2LDwD7pR1tZ",
        "outputId": "7f9e76b7-71ad-4354-bb1e-b9462111289c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMZojErBASGP",
        "outputId": "5ba95b77-ed87-4163-c72c-e367903ead9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1999"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "val_folder = \"/content/drive/MyDrive/deep_fake_image_detection/Image_segregated_2/val\"\n",
        "X_val, y_val = load_images_and_labels(val_folder)\n"
      ],
      "metadata": {
        "id": "m2lyubWoOKvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ-LganSRhct",
        "outputId": "33b1f909-ba11-4aec-c23f-e6f2ef2f2862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(810, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ0OmTrZRu-f",
        "outputId": "261e45eb-c856-4fb7-ee59-64bc134ba839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(810,)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JelLINYRxnf",
        "outputId": "f8cdc3b9-1110-4c85-a9dc-2d86b086913a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_folder = \"/content/drive/MyDrive/deep_fake_image_detection/Image_segregated_2/test\"\n",
        "X_test, y_test = load_images_and_labels(test_folder)\n"
      ],
      "metadata": {
        "id": "Aoc5sUAI-J85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch-x5P-2-J1V",
        "outputId": "aa4885f1-6eb8-41f7-e161-c1ff47734c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(819, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H12aVtd-JtN",
        "outputId": "d634b248-0eb2-48ff-f53f-38608e931fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(819,)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "## Generating data or images during runtime for training purpose.DO not do it for testing\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.2, # Randomly zoom image\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip = True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(X_train)\n"
      ],
      "metadata": {
        "id": "f7mdVK8jRzHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAfn95e6Sloa",
        "outputId": "b70a4d94-69b5-4be1-9890-1719e5b3d840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1999, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.optimizers import Adam\n",
        "\n"
      ],
      "metadata": {
        "id": "0SrJv6H0-uij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained ResNet50 model (excluding the top layer)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_BcK65n-uYN",
        "outputId": "2f1717a4-adc3-42ff-bd88-fdc1acafd5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model and add the pre-trained ResNet50 as a base\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification (real/fake)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNRsKPMV-uUn",
        "outputId": "20ae8c2f-2205-452b-f61b-a5eda074dfca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "RHWwKnWlA6JX",
        "outputId": "bb7fdfe0-6f4b-46c7-d29e-8fc90998a77a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 100352)            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               25690368  \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49278337 (187.98 MB)\n",
            "Trainable params: 25690625 (98.00 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You need to have your dataset in X_train and y_train (features and labels)\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "id": "4nN0a5xL-uRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Conv2D(128, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Conv2D(128, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Conv2D(256, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Conv2D(256, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(128,activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "Melsem9SSlmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwUUlDfjSlkJ",
        "outputId": "1b62ed90-eae9-4dd3-a4a2-fbbf488305ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 112, 112, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 3, 3, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 3, 3, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 1, 1, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1168353 (4.46 MB)\n",
            "Trainable params: 1168353 (4.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "opt = Adam(learning_rate=0.000001)\n",
        "model.compile(optimizer = opt , loss = \"binary_crossentropy\" , metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "7v56ggsBSliH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)"
      ],
      "metadata": {
        "id": "TAcQ--AlSle9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#history = model.fit(x_train,y_train,epochs = 10 , validation_data = (x_val, y_val))\n",
        "\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# train the model\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "hist = model.fit(X_train, y_train, batch_size=16, epochs=30,\n",
        "          validation_data=(X_val, y_val), callbacks=[checkpointer],\n",
        "          verbose=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ3athP_SlZW",
        "outputId": "86424421-2b38-4147-f671-ad78dde7726b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.00316, saving model to model.weights.best.hdf5\n",
            "125/125 - 193s - loss: 2.9300 - accuracy: 0.5038 - val_loss: 1.0032 - val_accuracy: 0.5200 - 193s/epoch - 2s/step\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_loss improved from 1.00316 to 0.66601, saving model to model.weights.best.hdf5\n",
            "125/125 - 188s - loss: 2.3218 - accuracy: 0.5058 - val_loss: 0.6660 - val_accuracy: 0.5925 - 188s/epoch - 2s/step\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 3: val_loss improved from 0.66601 to 0.60442, saving model to model.weights.best.hdf5\n",
            "125/125 - 187s - loss: 1.7977 - accuracy: 0.5448 - val_loss: 0.6044 - val_accuracy: 0.6413 - 187s/epoch - 1s/step\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 4: val_loss improved from 0.60442 to 0.53730, saving model to model.weights.best.hdf5\n",
            "125/125 - 185s - loss: 1.6979 - accuracy: 0.5518 - val_loss: 0.5373 - val_accuracy: 0.7125 - 185s/epoch - 1s/step\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 5: val_loss improved from 0.53730 to 0.43004, saving model to model.weights.best.hdf5\n",
            "125/125 - 188s - loss: 1.3580 - accuracy: 0.5923 - val_loss: 0.4300 - val_accuracy: 0.8325 - 188s/epoch - 2s/step\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 6: val_loss improved from 0.43004 to 0.39883, saving model to model.weights.best.hdf5\n",
            "125/125 - 193s - loss: 1.2860 - accuracy: 0.5963 - val_loss: 0.3988 - val_accuracy: 0.8600 - 193s/epoch - 2s/step\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 7: val_loss improved from 0.39883 to 0.38169, saving model to model.weights.best.hdf5\n",
            "125/125 - 188s - loss: 1.2560 - accuracy: 0.5918 - val_loss: 0.3817 - val_accuracy: 0.8637 - 188s/epoch - 2s/step\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 8: val_loss improved from 0.38169 to 0.36003, saving model to model.weights.best.hdf5\n",
            "125/125 - 191s - loss: 1.0157 - accuracy: 0.6303 - val_loss: 0.3600 - val_accuracy: 0.8838 - 191s/epoch - 2s/step\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 9: val_loss improved from 0.36003 to 0.33431, saving model to model.weights.best.hdf5\n",
            "125/125 - 186s - loss: 0.8757 - accuracy: 0.6503 - val_loss: 0.3343 - val_accuracy: 0.8913 - 186s/epoch - 1s/step\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 10: val_loss improved from 0.33431 to 0.31752, saving model to model.weights.best.hdf5\n",
            "125/125 - 187s - loss: 0.7649 - accuracy: 0.6893 - val_loss: 0.3175 - val_accuracy: 0.9050 - 187s/epoch - 1s/step\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 11: val_loss improved from 0.31752 to 0.30879, saving model to model.weights.best.hdf5\n",
            "125/125 - 189s - loss: 0.7641 - accuracy: 0.6983 - val_loss: 0.3088 - val_accuracy: 0.9112 - 189s/epoch - 2s/step\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 12: val_loss improved from 0.30879 to 0.29490, saving model to model.weights.best.hdf5\n",
            "125/125 - 187s - loss: 0.6899 - accuracy: 0.7134 - val_loss: 0.2949 - val_accuracy: 0.9038 - 187s/epoch - 1s/step\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 13: val_loss improved from 0.29490 to 0.28132, saving model to model.weights.best.hdf5\n",
            "125/125 - 186s - loss: 0.6323 - accuracy: 0.7269 - val_loss: 0.2813 - val_accuracy: 0.9187 - 186s/epoch - 1s/step\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 14: val_loss improved from 0.28132 to 0.27132, saving model to model.weights.best.hdf5\n",
            "125/125 - 185s - loss: 0.5900 - accuracy: 0.7549 - val_loss: 0.2713 - val_accuracy: 0.9200 - 185s/epoch - 1s/step\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 15: val_loss improved from 0.27132 to 0.26141, saving model to model.weights.best.hdf5\n",
            "125/125 - 187s - loss: 0.5638 - accuracy: 0.7594 - val_loss: 0.2614 - val_accuracy: 0.9237 - 187s/epoch - 1s/step\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 16: val_loss improved from 0.26141 to 0.25307, saving model to model.weights.best.hdf5\n",
            "125/125 - 189s - loss: 0.5417 - accuracy: 0.7639 - val_loss: 0.2531 - val_accuracy: 0.9225 - 189s/epoch - 2s/step\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 17: val_loss improved from 0.25307 to 0.24529, saving model to model.weights.best.hdf5\n",
            "125/125 - 188s - loss: 0.4926 - accuracy: 0.7879 - val_loss: 0.2453 - val_accuracy: 0.9325 - 188s/epoch - 2s/step\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 18: val_loss improved from 0.24529 to 0.23857, saving model to model.weights.best.hdf5\n",
            "125/125 - 187s - loss: 0.4875 - accuracy: 0.7884 - val_loss: 0.2386 - val_accuracy: 0.9237 - 187s/epoch - 1s/step\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 19: val_loss improved from 0.23857 to 0.22953, saving model to model.weights.best.hdf5\n",
            "125/125 - 188s - loss: 0.4470 - accuracy: 0.7974 - val_loss: 0.2295 - val_accuracy: 0.9262 - 188s/epoch - 2s/step\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 20: val_loss improved from 0.22953 to 0.22213, saving model to model.weights.best.hdf5\n",
            "125/125 - 188s - loss: 0.4371 - accuracy: 0.8059 - val_loss: 0.2221 - val_accuracy: 0.9300 - 188s/epoch - 2s/step\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 21: val_loss improved from 0.22213 to 0.21579, saving model to model.weights.best.hdf5\n",
            "125/125 - 189s - loss: 0.4057 - accuracy: 0.8259 - val_loss: 0.2158 - val_accuracy: 0.9300 - 189s/epoch - 2s/step\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 22: val_loss improved from 0.21579 to 0.20700, saving model to model.weights.best.hdf5\n",
            "125/125 - 187s - loss: 0.3874 - accuracy: 0.8274 - val_loss: 0.2070 - val_accuracy: 0.9337 - 187s/epoch - 1s/step\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 23: val_loss improved from 0.20700 to 0.20190, saving model to model.weights.best.hdf5\n",
            "125/125 - 188s - loss: 0.3709 - accuracy: 0.8464 - val_loss: 0.2019 - val_accuracy: 0.9325 - 188s/epoch - 2s/step\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 24: val_loss improved from 0.20190 to 0.20060, saving model to model.weights.best.hdf5\n",
            "125/125 - 188s - loss: 0.3383 - accuracy: 0.8594 - val_loss: 0.2006 - val_accuracy: 0.9312 - 188s/epoch - 2s/step\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.20060\n",
            "125/125 - 186s - loss: 0.3336 - accuracy: 0.8569 - val_loss: 0.2027 - val_accuracy: 0.9275 - 186s/epoch - 1s/step\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 26: val_loss improved from 0.20060 to 0.18180, saving model to model.weights.best.hdf5\n",
            "125/125 - 207s - loss: 0.3216 - accuracy: 0.8609 - val_loss: 0.1818 - val_accuracy: 0.9413 - 207s/epoch - 2s/step\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 27: val_loss improved from 0.18180 to 0.17224, saving model to model.weights.best.hdf5\n",
            "125/125 - 214s - loss: 0.2967 - accuracy: 0.8849 - val_loss: 0.1722 - val_accuracy: 0.9563 - 214s/epoch - 2s/step\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 28: val_loss improved from 0.17224 to 0.16473, saving model to model.weights.best.hdf5\n",
            "125/125 - 187s - loss: 0.3036 - accuracy: 0.8769 - val_loss: 0.1647 - val_accuracy: 0.9625 - 187s/epoch - 1s/step\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 29: val_loss improved from 0.16473 to 0.16097, saving model to model.weights.best.hdf5\n",
            "125/125 - 188s - loss: 0.2892 - accuracy: 0.8889 - val_loss: 0.1610 - val_accuracy: 0.9575 - 188s/epoch - 2s/step\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 30: val_loss improved from 0.16097 to 0.16023, saving model to model.weights.best.hdf5\n",
            "125/125 - 186s - loss: 0.2784 - accuracy: 0.8884 - val_loss: 0.1602 - val_accuracy: 0.9538 - 186s/epoch - 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rTO7-XY48d1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define a ModelCheckpoint callback to save the best weights during training\n",
        "checkpoint = ModelCheckpoint('model.weights.best.hdf5',  # Update with the desired filename\n",
        "                             save_best_only=True,         # Save only the best weights\n",
        "                             monitor='val_loss',          # Monitor validation loss\n",
        "                             mode='min',                  # Mode can be 'min' or 'max' depending on the metric\n",
        "                             verbose=1)\n",
        "\n",
        "# Assuming you already have a model, compile it before training\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the ModelCheckpoint callback\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val), callbacks=[checkpoint])\n",
        "\n",
        "# After 30 epochs, you can continue training with the saved weights\n",
        "# Load the model with the best weights\n",
        "model.load_weights('model.weights.best.hdf5')\n",
        "\n",
        "# Continue training for additional epochs\n",
        "history = model.fit(X_train, y_train, epochs=40, validation_data=(X_val, y_val), callbacks=[checkpoint])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53IJO2fP8drJ",
        "outputId": "d92b7724-d0ca-4467-f87c-d1c44db65a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.7291 - accuracy: 0.7759\n",
            "Epoch 1: val_loss improved from inf to 0.34841, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 121s 2s/step - loss: 0.7291 - accuracy: 0.7759 - val_loss: 0.3484 - val_accuracy: 0.8175\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - ETA: 0s - loss: 0.3111 - accuracy: 0.8954\n",
            "Epoch 2: val_loss improved from 0.34841 to 0.33706, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 110s 2s/step - loss: 0.3111 - accuracy: 0.8954 - val_loss: 0.3371 - val_accuracy: 0.9688\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.9390\n",
            "Epoch 3: val_loss improved from 0.33706 to 0.03333, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 117s 2s/step - loss: 0.1913 - accuracy: 0.9390 - val_loss: 0.0333 - val_accuracy: 0.9862\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9780\n",
            "Epoch 4: val_loss did not improve from 0.03333\n",
            "63/63 [==============================] - 117s 2s/step - loss: 0.0699 - accuracy: 0.9780 - val_loss: 0.0866 - val_accuracy: 0.9762\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.9345\n",
            "Epoch 5: val_loss did not improve from 0.03333\n",
            "63/63 [==============================] - 116s 2s/step - loss: 0.2209 - accuracy: 0.9345 - val_loss: 0.1308 - val_accuracy: 0.9613\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9670\n",
            "Epoch 6: val_loss did not improve from 0.03333\n",
            "63/63 [==============================] - 123s 2s/step - loss: 0.1068 - accuracy: 0.9670 - val_loss: 0.0382 - val_accuracy: 0.9900\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9800\n",
            "Epoch 7: val_loss improved from 0.03333 to 0.02074, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 117s 2s/step - loss: 0.0616 - accuracy: 0.9800 - val_loss: 0.0207 - val_accuracy: 0.9887\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9945\n",
            "Epoch 8: val_loss improved from 0.02074 to 0.00401, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 117s 2s/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9945\n",
            "Epoch 9: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 119s 2s/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0107 - val_accuracy: 0.9975\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.9630\n",
            "Epoch 10: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 108s 2s/step - loss: 0.1506 - accuracy: 0.9630 - val_loss: 0.0902 - val_accuracy: 0.9775\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.4975 - accuracy: 0.7969\n",
            "Epoch 11: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.4975 - accuracy: 0.7969 - val_loss: 0.6295 - val_accuracy: 0.6112\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.4144 - accuracy: 0.7904\n",
            "Epoch 12: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 108s 2s/step - loss: 0.4144 - accuracy: 0.7904 - val_loss: 0.2518 - val_accuracy: 0.9038\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.8409\n",
            "Epoch 13: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.3460 - accuracy: 0.8409 - val_loss: 0.2297 - val_accuracy: 0.9100\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.9255\n",
            "Epoch 14: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 116s 2s/step - loss: 0.1846 - accuracy: 0.9255 - val_loss: 0.0657 - val_accuracy: 0.9800\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9535\n",
            "Epoch 15: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.1220 - accuracy: 0.9535 - val_loss: 0.0684 - val_accuracy: 0.9812\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9810\n",
            "Epoch 16: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.0431 - accuracy: 0.9810 - val_loss: 0.0856 - val_accuracy: 0.9825\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9870\n",
            "Epoch 17: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 115s 2s/step - loss: 0.0392 - accuracy: 0.9870 - val_loss: 0.0311 - val_accuracy: 0.9925\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9915\n",
            "Epoch 18: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.0820 - val_accuracy: 0.9800\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9900\n",
            "Epoch 19: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 108s 2s/step - loss: 0.0267 - accuracy: 0.9900 - val_loss: 0.2150 - val_accuracy: 0.9438\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9725\n",
            "Epoch 20: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 108s 2s/step - loss: 0.0933 - accuracy: 0.9725 - val_loss: 0.0713 - val_accuracy: 0.9762\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9905\n",
            "Epoch 21: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 108s 2s/step - loss: 0.0247 - accuracy: 0.9905 - val_loss: 0.0786 - val_accuracy: 0.9787\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9915\n",
            "Epoch 22: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 118s 2s/step - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.0319 - val_accuracy: 0.9850\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9960\n",
            "Epoch 23: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 108s 2s/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.0276 - val_accuracy: 0.9875\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9960\n",
            "Epoch 24: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 117s 2s/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0256 - val_accuracy: 0.9887\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9965\n",
            "Epoch 25: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0196 - val_accuracy: 0.9937\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
            "Epoch 26: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0242 - val_accuracy: 0.9937\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 8.8618e-04 - accuracy: 0.9995\n",
            "Epoch 27: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 107s 2s/step - loss: 8.8618e-04 - accuracy: 0.9995 - val_loss: 0.0181 - val_accuracy: 0.9950\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 124s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9912\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9410\n",
            "Epoch 29: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 108s 2s/step - loss: 0.2078 - accuracy: 0.9410 - val_loss: 0.1885 - val_accuracy: 0.9312\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9675\n",
            "Epoch 30: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.0935 - accuracy: 0.9675 - val_loss: 0.1197 - val_accuracy: 0.9737\n",
            "Epoch 1/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9770\n",
            "Epoch 1: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 108s 2s/step - loss: 0.1118 - accuracy: 0.9770 - val_loss: 0.0983 - val_accuracy: 0.9600\n",
            "Epoch 2/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9710\n",
            "Epoch 2: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.0930 - accuracy: 0.9710 - val_loss: 0.0625 - val_accuracy: 0.9725\n",
            "Epoch 3/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9900\n",
            "Epoch 3: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 113s 2s/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.0259 - val_accuracy: 0.9912\n",
            "Epoch 4/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9915\n",
            "Epoch 4: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.0122 - val_accuracy: 0.9975\n",
            "Epoch 5/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9970\n",
            "Epoch 5: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.0061 - val_accuracy: 0.9975\n",
            "Epoch 6/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9920\n",
            "Epoch 6: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 116s 2s/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0361 - val_accuracy: 0.9862\n",
            "Epoch 7/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9810\n",
            "Epoch 7: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.0709 - accuracy: 0.9810 - val_loss: 0.1090 - val_accuracy: 0.9812\n",
            "Epoch 8/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9830\n",
            "Epoch 8: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 116s 2s/step - loss: 0.0825 - accuracy: 0.9830 - val_loss: 0.0372 - val_accuracy: 0.9875\n",
            "Epoch 9/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9975\n",
            "Epoch 9: val_loss did not improve from 0.00401\n",
            "63/63 [==============================] - 116s 2s/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0056 - val_accuracy: 0.9962\n",
            "Epoch 10/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9980\n",
            "Epoch 10: val_loss improved from 0.00401 to 0.00299, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 11/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9960\n",
            "Epoch 11: val_loss did not improve from 0.00299\n",
            "63/63 [==============================] - 115s 2s/step - loss: 0.0107 - accuracy: 0.9960 - val_loss: 0.0882 - val_accuracy: 0.9875\n",
            "Epoch 12/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9870\n",
            "Epoch 12: val_loss did not improve from 0.00299\n",
            "63/63 [==============================] - 108s 2s/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 0.0088 - val_accuracy: 0.9962\n",
            "Epoch 13/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9865\n",
            "Epoch 13: val_loss did not improve from 0.00299\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.0260 - accuracy: 0.9865 - val_loss: 0.0252 - val_accuracy: 0.9925\n",
            "Epoch 14/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9950\n",
            "Epoch 14: val_loss did not improve from 0.00299\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.0086 - accuracy: 0.9950 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 15/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9990\n",
            "Epoch 15: val_loss did not improve from 0.00299\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 0.0083 - val_accuracy: 0.9937\n",
            "Epoch 16/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9900\n",
            "Epoch 16: val_loss did not improve from 0.00299\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.0485 - accuracy: 0.9900 - val_loss: 0.1300 - val_accuracy: 0.9663\n",
            "Epoch 17/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9895\n",
            "Epoch 17: val_loss did not improve from 0.00299\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.0398 - accuracy: 0.9895 - val_loss: 0.0307 - val_accuracy: 0.9937\n",
            "Epoch 18/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9980\n",
            "Epoch 18: val_loss did not improve from 0.00299\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0112 - val_accuracy: 0.9987\n",
            "Epoch 19/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9970\n",
            "Epoch 19: val_loss did not improve from 0.00299\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.0058 - accuracy: 0.9970 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 20/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
            "Epoch 20: val_loss did not improve from 0.00299\n",
            "63/63 [==============================] - 116s 2s/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9975\n",
            "Epoch 21/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 21: val_loss improved from 0.00299 to 0.00276, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9975\n",
            "Epoch 22/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 7.1469e-04 - accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 0.00276\n",
            "63/63 [==============================] - 106s 2s/step - loss: 7.1469e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9975\n",
            "Epoch 23/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 4.1808e-04 - accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 0.00276\n",
            "63/63 [==============================] - 106s 2s/step - loss: 4.1808e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9975\n",
            "Epoch 24/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 3.1269e-04 - accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 0.00276\n",
            "63/63 [==============================] - 115s 2s/step - loss: 3.1269e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9975\n",
            "Epoch 25/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.0361e-04 - accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 0.00276\n",
            "63/63 [==============================] - 107s 2s/step - loss: 1.0361e-04 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9975\n",
            "Epoch 26/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 2.0194e-04 - accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 0.00276\n",
            "63/63 [==============================] - 121s 2s/step - loss: 2.0194e-04 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9925\n",
            "Epoch 27/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9795\n",
            "Epoch 27: val_loss did not improve from 0.00276\n",
            "63/63 [==============================] - 123s 2s/step - loss: 0.0879 - accuracy: 0.9795 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
            "Epoch 28/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9970\n",
            "Epoch 28: val_loss did not improve from 0.00276\n",
            "63/63 [==============================] - 109s 2s/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.0137 - val_accuracy: 0.9937\n",
            "Epoch 29/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9975\n",
            "Epoch 29: val_loss improved from 0.00276 to 0.00187, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 107s 2s/step - loss: 0.0041 - accuracy: 0.9975 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 30/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9980\n",
            "Epoch 30: val_loss improved from 0.00187 to 0.00105, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 116s 2s/step - loss: 0.0022 - accuracy: 0.9980 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 31/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9990\n",
            "Epoch 31: val_loss improved from 0.00105 to 0.00065, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 116s 2s/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 6.4604e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 9.7651e-04 - accuracy: 0.9995\n",
            "Epoch 32: val_loss improved from 0.00065 to 0.00050, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 106s 2s/step - loss: 9.7651e-04 - accuracy: 0.9995 - val_loss: 4.9863e-04 - val_accuracy: 1.0000\n",
            "Epoch 33/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 8.3523e-04 - accuracy: 1.0000\n",
            "Epoch 33: val_loss improved from 0.00050 to 0.00038, saving model to model.weights.best.hdf5\n",
            "63/63 [==============================] - 116s 2s/step - loss: 8.3523e-04 - accuracy: 1.0000 - val_loss: 3.8251e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2910 - accuracy: 0.8949\n",
            "Epoch 34: val_loss did not improve from 0.00038\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.2910 - accuracy: 0.8949 - val_loss: 0.7013 - val_accuracy: 0.5188\n",
            "Epoch 35/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.6523 - accuracy: 0.6748\n",
            "Epoch 35: val_loss did not improve from 0.00038\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.6523 - accuracy: 0.6748 - val_loss: 0.4815 - val_accuracy: 0.8050\n",
            "Epoch 36/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.8479\n",
            "Epoch 36: val_loss did not improve from 0.00038\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.3659 - accuracy: 0.8479 - val_loss: 0.2359 - val_accuracy: 0.8938\n",
            "Epoch 37/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.8374\n",
            "Epoch 37: val_loss did not improve from 0.00038\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.3924 - accuracy: 0.8374 - val_loss: 0.3307 - val_accuracy: 0.8850\n",
            "Epoch 38/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2669 - accuracy: 0.8899\n",
            "Epoch 38: val_loss did not improve from 0.00038\n",
            "63/63 [==============================] - 115s 2s/step - loss: 0.2669 - accuracy: 0.8899 - val_loss: 0.2249 - val_accuracy: 0.8925\n",
            "Epoch 39/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.8839\n",
            "Epoch 39: val_loss did not improve from 0.00038\n",
            "63/63 [==============================] - 115s 2s/step - loss: 0.2656 - accuracy: 0.8839 - val_loss: 0.2281 - val_accuracy: 0.8925\n",
            "Epoch 40/40\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9490\n",
            "Epoch 40: val_loss did not improve from 0.00038\n",
            "63/63 [==============================] - 106s 2s/step - loss: 0.1477 - accuracy: 0.9490 - val_loss: 0.1412 - val_accuracy: 0.9400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "epochs_range = range(30)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "VpdVBAt7SlXA",
        "outputId": "a07cc7ba-ad62-45f3-cb61-0cd26172a441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'hist' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-9cf0e095a7cd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "831x6I5qU9Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the new image\n",
        "img_path = '/content/drive/MyDrive/drive_folder/test/266489438_243956187692342_630767671687137816_n.jpg'  # Update with the path to your new image\n"
      ],
      "metadata": {
        "id": "9urvsjFXehgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(img_path)\n",
        "img = cv2.resize(img, (224, 224))  # Assuming the model was trained with input size (224, 224)\n",
        "img = img / 255.0  # Normalize pixel values to be in the range [0, 1]\n",
        "img = np.expand_dims(img, axis=0)  # Add batch dimension\n"
      ],
      "metadata": {
        "id": "itHxDIpbmIoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(img)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EPPX5SAehSe",
        "outputId": "70e851e5-01dc-4ed1-8d09-a6c25fed4610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)  # This will give you an array of probabilities for each class\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLFIrDD1ehOc",
        "outputId": "8196f062-1e9d-46ef-8093-e7761cea4cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.4947081]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5  # Adjust the threshold as needed\n",
        "predicted_class = 1 if predictions[0][0] > threshold else 0\n",
        "print(f'Predicted Class: {predicted_class}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-aq_QttehCV",
        "outputId": "4f60dd7a-7a35-40ce-fb82-272c846a0f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJfumFykeg-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BoQjYEIbeg63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yEHEVXvpeg23"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}