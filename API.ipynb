{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkSSSN0JhZeP",
        "outputId": "4b5ea256-652a-41e0-f3f9-e66591e25fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.0.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install Flask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "Eevi5FQBhi5j",
        "outputId": "16f60e4c-7bd4-47f9-b9b1-ca8e44da6463"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1ebbaff99638>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load the trained PyTorch model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/inceptionv3_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Define image transformations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained PyTorch model\n",
        "model = torch.load('/content/drive/MyDrive/inceptionv3_model.pth')\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def predict_image(image):\n",
        "    # Apply transformations\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        output = F.softmax(model(image), dim=1)\n",
        "\n",
        "    # Get predicted class\n",
        "    _, predicted = torch.max(output, 1)\n",
        "\n",
        "    return predicted.item()\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the uploaded image file from the request\n",
        "    file = request.files['image']\n",
        "\n",
        "    # Read the image file\n",
        "    img = Image.open(io.BytesIO(file.read()))\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = predict_image(img)\n",
        "\n",
        "    # Convert prediction to human-readable format\n",
        "    prediction_label = 'Real' if prediction == 0 else 'Fake'\n",
        "\n",
        "    # Return the prediction as JSON\n",
        "    return jsonify(prediction=prediction_label)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "FOol0d7UhmTI",
        "outputId": "78fb0383-b222-4e43-f405-91ad47775dda"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'model_state_dict'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-dd83d8890505>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Extract the model's state dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'model_state_dict'"
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "checkpoint = torch.load('/content/drive/MyDrive/inceptionv3_model.pth')\n",
        "\n",
        "# Extract the model's state dictionary\n",
        "model_state_dict = checkpoint['model_state_dict']\n",
        "\n",
        "# Load the model architecture\n",
        "model = InceptionV3()\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn3fzjQTh-P8",
        "outputId": "e65cd8a2-6f27-459d-e429-d91125e63359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['base_model.Conv2d_1a_3x3.conv.weight', 'base_model.Conv2d_1a_3x3.bn.weight', 'base_model.Conv2d_1a_3x3.bn.bias', 'base_model.Conv2d_1a_3x3.bn.running_mean', 'base_model.Conv2d_1a_3x3.bn.running_var', 'base_model.Conv2d_1a_3x3.bn.num_batches_tracked', 'base_model.Conv2d_2a_3x3.conv.weight', 'base_model.Conv2d_2a_3x3.bn.weight', 'base_model.Conv2d_2a_3x3.bn.bias', 'base_model.Conv2d_2a_3x3.bn.running_mean', 'base_model.Conv2d_2a_3x3.bn.running_var', 'base_model.Conv2d_2a_3x3.bn.num_batches_tracked', 'base_model.Conv2d_2b_3x3.conv.weight', 'base_model.Conv2d_2b_3x3.bn.weight', 'base_model.Conv2d_2b_3x3.bn.bias', 'base_model.Conv2d_2b_3x3.bn.running_mean', 'base_model.Conv2d_2b_3x3.bn.running_var', 'base_model.Conv2d_2b_3x3.bn.num_batches_tracked', 'base_model.Conv2d_3b_1x1.conv.weight', 'base_model.Conv2d_3b_1x1.bn.weight', 'base_model.Conv2d_3b_1x1.bn.bias', 'base_model.Conv2d_3b_1x1.bn.running_mean', 'base_model.Conv2d_3b_1x1.bn.running_var', 'base_model.Conv2d_3b_1x1.bn.num_batches_tracked', 'base_model.Conv2d_4a_3x3.conv.weight', 'base_model.Conv2d_4a_3x3.bn.weight', 'base_model.Conv2d_4a_3x3.bn.bias', 'base_model.Conv2d_4a_3x3.bn.running_mean', 'base_model.Conv2d_4a_3x3.bn.running_var', 'base_model.Conv2d_4a_3x3.bn.num_batches_tracked', 'base_model.Mixed_5b.branch1x1.conv.weight', 'base_model.Mixed_5b.branch1x1.bn.weight', 'base_model.Mixed_5b.branch1x1.bn.bias', 'base_model.Mixed_5b.branch1x1.bn.running_mean', 'base_model.Mixed_5b.branch1x1.bn.running_var', 'base_model.Mixed_5b.branch1x1.bn.num_batches_tracked', 'base_model.Mixed_5b.branch5x5_1.conv.weight', 'base_model.Mixed_5b.branch5x5_1.bn.weight', 'base_model.Mixed_5b.branch5x5_1.bn.bias', 'base_model.Mixed_5b.branch5x5_1.bn.running_mean', 'base_model.Mixed_5b.branch5x5_1.bn.running_var', 'base_model.Mixed_5b.branch5x5_1.bn.num_batches_tracked', 'base_model.Mixed_5b.branch5x5_2.conv.weight', 'base_model.Mixed_5b.branch5x5_2.bn.weight', 'base_model.Mixed_5b.branch5x5_2.bn.bias', 'base_model.Mixed_5b.branch5x5_2.bn.running_mean', 'base_model.Mixed_5b.branch5x5_2.bn.running_var', 'base_model.Mixed_5b.branch5x5_2.bn.num_batches_tracked', 'base_model.Mixed_5b.branch3x3dbl_1.conv.weight', 'base_model.Mixed_5b.branch3x3dbl_1.bn.weight', 'base_model.Mixed_5b.branch3x3dbl_1.bn.bias', 'base_model.Mixed_5b.branch3x3dbl_1.bn.running_mean', 'base_model.Mixed_5b.branch3x3dbl_1.bn.running_var', 'base_model.Mixed_5b.branch3x3dbl_1.bn.num_batches_tracked', 'base_model.Mixed_5b.branch3x3dbl_2.conv.weight', 'base_model.Mixed_5b.branch3x3dbl_2.bn.weight', 'base_model.Mixed_5b.branch3x3dbl_2.bn.bias', 'base_model.Mixed_5b.branch3x3dbl_2.bn.running_mean', 'base_model.Mixed_5b.branch3x3dbl_2.bn.running_var', 'base_model.Mixed_5b.branch3x3dbl_2.bn.num_batches_tracked', 'base_model.Mixed_5b.branch3x3dbl_3.conv.weight', 'base_model.Mixed_5b.branch3x3dbl_3.bn.weight', 'base_model.Mixed_5b.branch3x3dbl_3.bn.bias', 'base_model.Mixed_5b.branch3x3dbl_3.bn.running_mean', 'base_model.Mixed_5b.branch3x3dbl_3.bn.running_var', 'base_model.Mixed_5b.branch3x3dbl_3.bn.num_batches_tracked', 'base_model.Mixed_5b.branch_pool.conv.weight', 'base_model.Mixed_5b.branch_pool.bn.weight', 'base_model.Mixed_5b.branch_pool.bn.bias', 'base_model.Mixed_5b.branch_pool.bn.running_mean', 'base_model.Mixed_5b.branch_pool.bn.running_var', 'base_model.Mixed_5b.branch_pool.bn.num_batches_tracked', 'base_model.Mixed_5c.branch1x1.conv.weight', 'base_model.Mixed_5c.branch1x1.bn.weight', 'base_model.Mixed_5c.branch1x1.bn.bias', 'base_model.Mixed_5c.branch1x1.bn.running_mean', 'base_model.Mixed_5c.branch1x1.bn.running_var', 'base_model.Mixed_5c.branch1x1.bn.num_batches_tracked', 'base_model.Mixed_5c.branch5x5_1.conv.weight', 'base_model.Mixed_5c.branch5x5_1.bn.weight', 'base_model.Mixed_5c.branch5x5_1.bn.bias', 'base_model.Mixed_5c.branch5x5_1.bn.running_mean', 'base_model.Mixed_5c.branch5x5_1.bn.running_var', 'base_model.Mixed_5c.branch5x5_1.bn.num_batches_tracked', 'base_model.Mixed_5c.branch5x5_2.conv.weight', 'base_model.Mixed_5c.branch5x5_2.bn.weight', 'base_model.Mixed_5c.branch5x5_2.bn.bias', 'base_model.Mixed_5c.branch5x5_2.bn.running_mean', 'base_model.Mixed_5c.branch5x5_2.bn.running_var', 'base_model.Mixed_5c.branch5x5_2.bn.num_batches_tracked', 'base_model.Mixed_5c.branch3x3dbl_1.conv.weight', 'base_model.Mixed_5c.branch3x3dbl_1.bn.weight', 'base_model.Mixed_5c.branch3x3dbl_1.bn.bias', 'base_model.Mixed_5c.branch3x3dbl_1.bn.running_mean', 'base_model.Mixed_5c.branch3x3dbl_1.bn.running_var', 'base_model.Mixed_5c.branch3x3dbl_1.bn.num_batches_tracked', 'base_model.Mixed_5c.branch3x3dbl_2.conv.weight', 'base_model.Mixed_5c.branch3x3dbl_2.bn.weight', 'base_model.Mixed_5c.branch3x3dbl_2.bn.bias', 'base_model.Mixed_5c.branch3x3dbl_2.bn.running_mean', 'base_model.Mixed_5c.branch3x3dbl_2.bn.running_var', 'base_model.Mixed_5c.branch3x3dbl_2.bn.num_batches_tracked', 'base_model.Mixed_5c.branch3x3dbl_3.conv.weight', 'base_model.Mixed_5c.branch3x3dbl_3.bn.weight', 'base_model.Mixed_5c.branch3x3dbl_3.bn.bias', 'base_model.Mixed_5c.branch3x3dbl_3.bn.running_mean', 'base_model.Mixed_5c.branch3x3dbl_3.bn.running_var', 'base_model.Mixed_5c.branch3x3dbl_3.bn.num_batches_tracked', 'base_model.Mixed_5c.branch_pool.conv.weight', 'base_model.Mixed_5c.branch_pool.bn.weight', 'base_model.Mixed_5c.branch_pool.bn.bias', 'base_model.Mixed_5c.branch_pool.bn.running_mean', 'base_model.Mixed_5c.branch_pool.bn.running_var', 'base_model.Mixed_5c.branch_pool.bn.num_batches_tracked', 'base_model.Mixed_5d.branch1x1.conv.weight', 'base_model.Mixed_5d.branch1x1.bn.weight', 'base_model.Mixed_5d.branch1x1.bn.bias', 'base_model.Mixed_5d.branch1x1.bn.running_mean', 'base_model.Mixed_5d.branch1x1.bn.running_var', 'base_model.Mixed_5d.branch1x1.bn.num_batches_tracked', 'base_model.Mixed_5d.branch5x5_1.conv.weight', 'base_model.Mixed_5d.branch5x5_1.bn.weight', 'base_model.Mixed_5d.branch5x5_1.bn.bias', 'base_model.Mixed_5d.branch5x5_1.bn.running_mean', 'base_model.Mixed_5d.branch5x5_1.bn.running_var', 'base_model.Mixed_5d.branch5x5_1.bn.num_batches_tracked', 'base_model.Mixed_5d.branch5x5_2.conv.weight', 'base_model.Mixed_5d.branch5x5_2.bn.weight', 'base_model.Mixed_5d.branch5x5_2.bn.bias', 'base_model.Mixed_5d.branch5x5_2.bn.running_mean', 'base_model.Mixed_5d.branch5x5_2.bn.running_var', 'base_model.Mixed_5d.branch5x5_2.bn.num_batches_tracked', 'base_model.Mixed_5d.branch3x3dbl_1.conv.weight', 'base_model.Mixed_5d.branch3x3dbl_1.bn.weight', 'base_model.Mixed_5d.branch3x3dbl_1.bn.bias', 'base_model.Mixed_5d.branch3x3dbl_1.bn.running_mean', 'base_model.Mixed_5d.branch3x3dbl_1.bn.running_var', 'base_model.Mixed_5d.branch3x3dbl_1.bn.num_batches_tracked', 'base_model.Mixed_5d.branch3x3dbl_2.conv.weight', 'base_model.Mixed_5d.branch3x3dbl_2.bn.weight', 'base_model.Mixed_5d.branch3x3dbl_2.bn.bias', 'base_model.Mixed_5d.branch3x3dbl_2.bn.running_mean', 'base_model.Mixed_5d.branch3x3dbl_2.bn.running_var', 'base_model.Mixed_5d.branch3x3dbl_2.bn.num_batches_tracked', 'base_model.Mixed_5d.branch3x3dbl_3.conv.weight', 'base_model.Mixed_5d.branch3x3dbl_3.bn.weight', 'base_model.Mixed_5d.branch3x3dbl_3.bn.bias', 'base_model.Mixed_5d.branch3x3dbl_3.bn.running_mean', 'base_model.Mixed_5d.branch3x3dbl_3.bn.running_var', 'base_model.Mixed_5d.branch3x3dbl_3.bn.num_batches_tracked', 'base_model.Mixed_5d.branch_pool.conv.weight', 'base_model.Mixed_5d.branch_pool.bn.weight', 'base_model.Mixed_5d.branch_pool.bn.bias', 'base_model.Mixed_5d.branch_pool.bn.running_mean', 'base_model.Mixed_5d.branch_pool.bn.running_var', 'base_model.Mixed_5d.branch_pool.bn.num_batches_tracked', 'base_model.Mixed_6a.branch3x3.conv.weight', 'base_model.Mixed_6a.branch3x3.bn.weight', 'base_model.Mixed_6a.branch3x3.bn.bias', 'base_model.Mixed_6a.branch3x3.bn.running_mean', 'base_model.Mixed_6a.branch3x3.bn.running_var', 'base_model.Mixed_6a.branch3x3.bn.num_batches_tracked', 'base_model.Mixed_6a.branch3x3dbl_1.conv.weight', 'base_model.Mixed_6a.branch3x3dbl_1.bn.weight', 'base_model.Mixed_6a.branch3x3dbl_1.bn.bias', 'base_model.Mixed_6a.branch3x3dbl_1.bn.running_mean', 'base_model.Mixed_6a.branch3x3dbl_1.bn.running_var', 'base_model.Mixed_6a.branch3x3dbl_1.bn.num_batches_tracked', 'base_model.Mixed_6a.branch3x3dbl_2.conv.weight', 'base_model.Mixed_6a.branch3x3dbl_2.bn.weight', 'base_model.Mixed_6a.branch3x3dbl_2.bn.bias', 'base_model.Mixed_6a.branch3x3dbl_2.bn.running_mean', 'base_model.Mixed_6a.branch3x3dbl_2.bn.running_var', 'base_model.Mixed_6a.branch3x3dbl_2.bn.num_batches_tracked', 'base_model.Mixed_6a.branch3x3dbl_3.conv.weight', 'base_model.Mixed_6a.branch3x3dbl_3.bn.weight', 'base_model.Mixed_6a.branch3x3dbl_3.bn.bias', 'base_model.Mixed_6a.branch3x3dbl_3.bn.running_mean', 'base_model.Mixed_6a.branch3x3dbl_3.bn.running_var', 'base_model.Mixed_6a.branch3x3dbl_3.bn.num_batches_tracked', 'base_model.Mixed_6b.branch1x1.conv.weight', 'base_model.Mixed_6b.branch1x1.bn.weight', 'base_model.Mixed_6b.branch1x1.bn.bias', 'base_model.Mixed_6b.branch1x1.bn.running_mean', 'base_model.Mixed_6b.branch1x1.bn.running_var', 'base_model.Mixed_6b.branch1x1.bn.num_batches_tracked', 'base_model.Mixed_6b.branch7x7_1.conv.weight', 'base_model.Mixed_6b.branch7x7_1.bn.weight', 'base_model.Mixed_6b.branch7x7_1.bn.bias', 'base_model.Mixed_6b.branch7x7_1.bn.running_mean', 'base_model.Mixed_6b.branch7x7_1.bn.running_var', 'base_model.Mixed_6b.branch7x7_1.bn.num_batches_tracked', 'base_model.Mixed_6b.branch7x7_2.conv.weight', 'base_model.Mixed_6b.branch7x7_2.bn.weight', 'base_model.Mixed_6b.branch7x7_2.bn.bias', 'base_model.Mixed_6b.branch7x7_2.bn.running_mean', 'base_model.Mixed_6b.branch7x7_2.bn.running_var', 'base_model.Mixed_6b.branch7x7_2.bn.num_batches_tracked', 'base_model.Mixed_6b.branch7x7_3.conv.weight', 'base_model.Mixed_6b.branch7x7_3.bn.weight', 'base_model.Mixed_6b.branch7x7_3.bn.bias', 'base_model.Mixed_6b.branch7x7_3.bn.running_mean', 'base_model.Mixed_6b.branch7x7_3.bn.running_var', 'base_model.Mixed_6b.branch7x7_3.bn.num_batches_tracked', 'base_model.Mixed_6b.branch7x7dbl_1.conv.weight', 'base_model.Mixed_6b.branch7x7dbl_1.bn.weight', 'base_model.Mixed_6b.branch7x7dbl_1.bn.bias', 'base_model.Mixed_6b.branch7x7dbl_1.bn.running_mean', 'base_model.Mixed_6b.branch7x7dbl_1.bn.running_var', 'base_model.Mixed_6b.branch7x7dbl_1.bn.num_batches_tracked', 'base_model.Mixed_6b.branch7x7dbl_2.conv.weight', 'base_model.Mixed_6b.branch7x7dbl_2.bn.weight', 'base_model.Mixed_6b.branch7x7dbl_2.bn.bias', 'base_model.Mixed_6b.branch7x7dbl_2.bn.running_mean', 'base_model.Mixed_6b.branch7x7dbl_2.bn.running_var', 'base_model.Mixed_6b.branch7x7dbl_2.bn.num_batches_tracked', 'base_model.Mixed_6b.branch7x7dbl_3.conv.weight', 'base_model.Mixed_6b.branch7x7dbl_3.bn.weight', 'base_model.Mixed_6b.branch7x7dbl_3.bn.bias', 'base_model.Mixed_6b.branch7x7dbl_3.bn.running_mean', 'base_model.Mixed_6b.branch7x7dbl_3.bn.running_var', 'base_model.Mixed_6b.branch7x7dbl_3.bn.num_batches_tracked', 'base_model.Mixed_6b.branch7x7dbl_4.conv.weight', 'base_model.Mixed_6b.branch7x7dbl_4.bn.weight', 'base_model.Mixed_6b.branch7x7dbl_4.bn.bias', 'base_model.Mixed_6b.branch7x7dbl_4.bn.running_mean', 'base_model.Mixed_6b.branch7x7dbl_4.bn.running_var', 'base_model.Mixed_6b.branch7x7dbl_4.bn.num_batches_tracked', 'base_model.Mixed_6b.branch7x7dbl_5.conv.weight', 'base_model.Mixed_6b.branch7x7dbl_5.bn.weight', 'base_model.Mixed_6b.branch7x7dbl_5.bn.bias', 'base_model.Mixed_6b.branch7x7dbl_5.bn.running_mean', 'base_model.Mixed_6b.branch7x7dbl_5.bn.running_var', 'base_model.Mixed_6b.branch7x7dbl_5.bn.num_batches_tracked', 'base_model.Mixed_6b.branch_pool.conv.weight', 'base_model.Mixed_6b.branch_pool.bn.weight', 'base_model.Mixed_6b.branch_pool.bn.bias', 'base_model.Mixed_6b.branch_pool.bn.running_mean', 'base_model.Mixed_6b.branch_pool.bn.running_var', 'base_model.Mixed_6b.branch_pool.bn.num_batches_tracked', 'base_model.Mixed_6c.branch1x1.conv.weight', 'base_model.Mixed_6c.branch1x1.bn.weight', 'base_model.Mixed_6c.branch1x1.bn.bias', 'base_model.Mixed_6c.branch1x1.bn.running_mean', 'base_model.Mixed_6c.branch1x1.bn.running_var', 'base_model.Mixed_6c.branch1x1.bn.num_batches_tracked', 'base_model.Mixed_6c.branch7x7_1.conv.weight', 'base_model.Mixed_6c.branch7x7_1.bn.weight', 'base_model.Mixed_6c.branch7x7_1.bn.bias', 'base_model.Mixed_6c.branch7x7_1.bn.running_mean', 'base_model.Mixed_6c.branch7x7_1.bn.running_var', 'base_model.Mixed_6c.branch7x7_1.bn.num_batches_tracked', 'base_model.Mixed_6c.branch7x7_2.conv.weight', 'base_model.Mixed_6c.branch7x7_2.bn.weight', 'base_model.Mixed_6c.branch7x7_2.bn.bias', 'base_model.Mixed_6c.branch7x7_2.bn.running_mean', 'base_model.Mixed_6c.branch7x7_2.bn.running_var', 'base_model.Mixed_6c.branch7x7_2.bn.num_batches_tracked', 'base_model.Mixed_6c.branch7x7_3.conv.weight', 'base_model.Mixed_6c.branch7x7_3.bn.weight', 'base_model.Mixed_6c.branch7x7_3.bn.bias', 'base_model.Mixed_6c.branch7x7_3.bn.running_mean', 'base_model.Mixed_6c.branch7x7_3.bn.running_var', 'base_model.Mixed_6c.branch7x7_3.bn.num_batches_tracked', 'base_model.Mixed_6c.branch7x7dbl_1.conv.weight', 'base_model.Mixed_6c.branch7x7dbl_1.bn.weight', 'base_model.Mixed_6c.branch7x7dbl_1.bn.bias', 'base_model.Mixed_6c.branch7x7dbl_1.bn.running_mean', 'base_model.Mixed_6c.branch7x7dbl_1.bn.running_var', 'base_model.Mixed_6c.branch7x7dbl_1.bn.num_batches_tracked', 'base_model.Mixed_6c.branch7x7dbl_2.conv.weight', 'base_model.Mixed_6c.branch7x7dbl_2.bn.weight', 'base_model.Mixed_6c.branch7x7dbl_2.bn.bias', 'base_model.Mixed_6c.branch7x7dbl_2.bn.running_mean', 'base_model.Mixed_6c.branch7x7dbl_2.bn.running_var', 'base_model.Mixed_6c.branch7x7dbl_2.bn.num_batches_tracked', 'base_model.Mixed_6c.branch7x7dbl_3.conv.weight', 'base_model.Mixed_6c.branch7x7dbl_3.bn.weight', 'base_model.Mixed_6c.branch7x7dbl_3.bn.bias', 'base_model.Mixed_6c.branch7x7dbl_3.bn.running_mean', 'base_model.Mixed_6c.branch7x7dbl_3.bn.running_var', 'base_model.Mixed_6c.branch7x7dbl_3.bn.num_batches_tracked', 'base_model.Mixed_6c.branch7x7dbl_4.conv.weight', 'base_model.Mixed_6c.branch7x7dbl_4.bn.weight', 'base_model.Mixed_6c.branch7x7dbl_4.bn.bias', 'base_model.Mixed_6c.branch7x7dbl_4.bn.running_mean', 'base_model.Mixed_6c.branch7x7dbl_4.bn.running_var', 'base_model.Mixed_6c.branch7x7dbl_4.bn.num_batches_tracked', 'base_model.Mixed_6c.branch7x7dbl_5.conv.weight', 'base_model.Mixed_6c.branch7x7dbl_5.bn.weight', 'base_model.Mixed_6c.branch7x7dbl_5.bn.bias', 'base_model.Mixed_6c.branch7x7dbl_5.bn.running_mean', 'base_model.Mixed_6c.branch7x7dbl_5.bn.running_var', 'base_model.Mixed_6c.branch7x7dbl_5.bn.num_batches_tracked', 'base_model.Mixed_6c.branch_pool.conv.weight', 'base_model.Mixed_6c.branch_pool.bn.weight', 'base_model.Mixed_6c.branch_pool.bn.bias', 'base_model.Mixed_6c.branch_pool.bn.running_mean', 'base_model.Mixed_6c.branch_pool.bn.running_var', 'base_model.Mixed_6c.branch_pool.bn.num_batches_tracked', 'base_model.Mixed_6d.branch1x1.conv.weight', 'base_model.Mixed_6d.branch1x1.bn.weight', 'base_model.Mixed_6d.branch1x1.bn.bias', 'base_model.Mixed_6d.branch1x1.bn.running_mean', 'base_model.Mixed_6d.branch1x1.bn.running_var', 'base_model.Mixed_6d.branch1x1.bn.num_batches_tracked', 'base_model.Mixed_6d.branch7x7_1.conv.weight', 'base_model.Mixed_6d.branch7x7_1.bn.weight', 'base_model.Mixed_6d.branch7x7_1.bn.bias', 'base_model.Mixed_6d.branch7x7_1.bn.running_mean', 'base_model.Mixed_6d.branch7x7_1.bn.running_var', 'base_model.Mixed_6d.branch7x7_1.bn.num_batches_tracked', 'base_model.Mixed_6d.branch7x7_2.conv.weight', 'base_model.Mixed_6d.branch7x7_2.bn.weight', 'base_model.Mixed_6d.branch7x7_2.bn.bias', 'base_model.Mixed_6d.branch7x7_2.bn.running_mean', 'base_model.Mixed_6d.branch7x7_2.bn.running_var', 'base_model.Mixed_6d.branch7x7_2.bn.num_batches_tracked', 'base_model.Mixed_6d.branch7x7_3.conv.weight', 'base_model.Mixed_6d.branch7x7_3.bn.weight', 'base_model.Mixed_6d.branch7x7_3.bn.bias', 'base_model.Mixed_6d.branch7x7_3.bn.running_mean', 'base_model.Mixed_6d.branch7x7_3.bn.running_var', 'base_model.Mixed_6d.branch7x7_3.bn.num_batches_tracked', 'base_model.Mixed_6d.branch7x7dbl_1.conv.weight', 'base_model.Mixed_6d.branch7x7dbl_1.bn.weight', 'base_model.Mixed_6d.branch7x7dbl_1.bn.bias', 'base_model.Mixed_6d.branch7x7dbl_1.bn.running_mean', 'base_model.Mixed_6d.branch7x7dbl_1.bn.running_var', 'base_model.Mixed_6d.branch7x7dbl_1.bn.num_batches_tracked', 'base_model.Mixed_6d.branch7x7dbl_2.conv.weight', 'base_model.Mixed_6d.branch7x7dbl_2.bn.weight', 'base_model.Mixed_6d.branch7x7dbl_2.bn.bias', 'base_model.Mixed_6d.branch7x7dbl_2.bn.running_mean', 'base_model.Mixed_6d.branch7x7dbl_2.bn.running_var', 'base_model.Mixed_6d.branch7x7dbl_2.bn.num_batches_tracked', 'base_model.Mixed_6d.branch7x7dbl_3.conv.weight', 'base_model.Mixed_6d.branch7x7dbl_3.bn.weight', 'base_model.Mixed_6d.branch7x7dbl_3.bn.bias', 'base_model.Mixed_6d.branch7x7dbl_3.bn.running_mean', 'base_model.Mixed_6d.branch7x7dbl_3.bn.running_var', 'base_model.Mixed_6d.branch7x7dbl_3.bn.num_batches_tracked', 'base_model.Mixed_6d.branch7x7dbl_4.conv.weight', 'base_model.Mixed_6d.branch7x7dbl_4.bn.weight', 'base_model.Mixed_6d.branch7x7dbl_4.bn.bias', 'base_model.Mixed_6d.branch7x7dbl_4.bn.running_mean', 'base_model.Mixed_6d.branch7x7dbl_4.bn.running_var', 'base_model.Mixed_6d.branch7x7dbl_4.bn.num_batches_tracked', 'base_model.Mixed_6d.branch7x7dbl_5.conv.weight', 'base_model.Mixed_6d.branch7x7dbl_5.bn.weight', 'base_model.Mixed_6d.branch7x7dbl_5.bn.bias', 'base_model.Mixed_6d.branch7x7dbl_5.bn.running_mean', 'base_model.Mixed_6d.branch7x7dbl_5.bn.running_var', 'base_model.Mixed_6d.branch7x7dbl_5.bn.num_batches_tracked', 'base_model.Mixed_6d.branch_pool.conv.weight', 'base_model.Mixed_6d.branch_pool.bn.weight', 'base_model.Mixed_6d.branch_pool.bn.bias', 'base_model.Mixed_6d.branch_pool.bn.running_mean', 'base_model.Mixed_6d.branch_pool.bn.running_var', 'base_model.Mixed_6d.branch_pool.bn.num_batches_tracked', 'base_model.Mixed_6e.branch1x1.conv.weight', 'base_model.Mixed_6e.branch1x1.bn.weight', 'base_model.Mixed_6e.branch1x1.bn.bias', 'base_model.Mixed_6e.branch1x1.bn.running_mean', 'base_model.Mixed_6e.branch1x1.bn.running_var', 'base_model.Mixed_6e.branch1x1.bn.num_batches_tracked', 'base_model.Mixed_6e.branch7x7_1.conv.weight', 'base_model.Mixed_6e.branch7x7_1.bn.weight', 'base_model.Mixed_6e.branch7x7_1.bn.bias', 'base_model.Mixed_6e.branch7x7_1.bn.running_mean', 'base_model.Mixed_6e.branch7x7_1.bn.running_var', 'base_model.Mixed_6e.branch7x7_1.bn.num_batches_tracked', 'base_model.Mixed_6e.branch7x7_2.conv.weight', 'base_model.Mixed_6e.branch7x7_2.bn.weight', 'base_model.Mixed_6e.branch7x7_2.bn.bias', 'base_model.Mixed_6e.branch7x7_2.bn.running_mean', 'base_model.Mixed_6e.branch7x7_2.bn.running_var', 'base_model.Mixed_6e.branch7x7_2.bn.num_batches_tracked', 'base_model.Mixed_6e.branch7x7_3.conv.weight', 'base_model.Mixed_6e.branch7x7_3.bn.weight', 'base_model.Mixed_6e.branch7x7_3.bn.bias', 'base_model.Mixed_6e.branch7x7_3.bn.running_mean', 'base_model.Mixed_6e.branch7x7_3.bn.running_var', 'base_model.Mixed_6e.branch7x7_3.bn.num_batches_tracked', 'base_model.Mixed_6e.branch7x7dbl_1.conv.weight', 'base_model.Mixed_6e.branch7x7dbl_1.bn.weight', 'base_model.Mixed_6e.branch7x7dbl_1.bn.bias', 'base_model.Mixed_6e.branch7x7dbl_1.bn.running_mean', 'base_model.Mixed_6e.branch7x7dbl_1.bn.running_var', 'base_model.Mixed_6e.branch7x7dbl_1.bn.num_batches_tracked', 'base_model.Mixed_6e.branch7x7dbl_2.conv.weight', 'base_model.Mixed_6e.branch7x7dbl_2.bn.weight', 'base_model.Mixed_6e.branch7x7dbl_2.bn.bias', 'base_model.Mixed_6e.branch7x7dbl_2.bn.running_mean', 'base_model.Mixed_6e.branch7x7dbl_2.bn.running_var', 'base_model.Mixed_6e.branch7x7dbl_2.bn.num_batches_tracked', 'base_model.Mixed_6e.branch7x7dbl_3.conv.weight', 'base_model.Mixed_6e.branch7x7dbl_3.bn.weight', 'base_model.Mixed_6e.branch7x7dbl_3.bn.bias', 'base_model.Mixed_6e.branch7x7dbl_3.bn.running_mean', 'base_model.Mixed_6e.branch7x7dbl_3.bn.running_var', 'base_model.Mixed_6e.branch7x7dbl_3.bn.num_batches_tracked', 'base_model.Mixed_6e.branch7x7dbl_4.conv.weight', 'base_model.Mixed_6e.branch7x7dbl_4.bn.weight', 'base_model.Mixed_6e.branch7x7dbl_4.bn.bias', 'base_model.Mixed_6e.branch7x7dbl_4.bn.running_mean', 'base_model.Mixed_6e.branch7x7dbl_4.bn.running_var', 'base_model.Mixed_6e.branch7x7dbl_4.bn.num_batches_tracked', 'base_model.Mixed_6e.branch7x7dbl_5.conv.weight', 'base_model.Mixed_6e.branch7x7dbl_5.bn.weight', 'base_model.Mixed_6e.branch7x7dbl_5.bn.bias', 'base_model.Mixed_6e.branch7x7dbl_5.bn.running_mean', 'base_model.Mixed_6e.branch7x7dbl_5.bn.running_var', 'base_model.Mixed_6e.branch7x7dbl_5.bn.num_batches_tracked', 'base_model.Mixed_6e.branch_pool.conv.weight', 'base_model.Mixed_6e.branch_pool.bn.weight', 'base_model.Mixed_6e.branch_pool.bn.bias', 'base_model.Mixed_6e.branch_pool.bn.running_mean', 'base_model.Mixed_6e.branch_pool.bn.running_var', 'base_model.Mixed_6e.branch_pool.bn.num_batches_tracked', 'base_model.AuxLogits.conv0.conv.weight', 'base_model.AuxLogits.conv0.bn.weight', 'base_model.AuxLogits.conv0.bn.bias', 'base_model.AuxLogits.conv0.bn.running_mean', 'base_model.AuxLogits.conv0.bn.running_var', 'base_model.AuxLogits.conv0.bn.num_batches_tracked', 'base_model.AuxLogits.conv1.conv.weight', 'base_model.AuxLogits.conv1.bn.weight', 'base_model.AuxLogits.conv1.bn.bias', 'base_model.AuxLogits.conv1.bn.running_mean', 'base_model.AuxLogits.conv1.bn.running_var', 'base_model.AuxLogits.conv1.bn.num_batches_tracked', 'base_model.AuxLogits.fc.weight', 'base_model.AuxLogits.fc.bias', 'base_model.Mixed_7a.branch3x3_1.conv.weight', 'base_model.Mixed_7a.branch3x3_1.bn.weight', 'base_model.Mixed_7a.branch3x3_1.bn.bias', 'base_model.Mixed_7a.branch3x3_1.bn.running_mean', 'base_model.Mixed_7a.branch3x3_1.bn.running_var', 'base_model.Mixed_7a.branch3x3_1.bn.num_batches_tracked', 'base_model.Mixed_7a.branch3x3_2.conv.weight', 'base_model.Mixed_7a.branch3x3_2.bn.weight', 'base_model.Mixed_7a.branch3x3_2.bn.bias', 'base_model.Mixed_7a.branch3x3_2.bn.running_mean', 'base_model.Mixed_7a.branch3x3_2.bn.running_var', 'base_model.Mixed_7a.branch3x3_2.bn.num_batches_tracked', 'base_model.Mixed_7a.branch7x7x3_1.conv.weight', 'base_model.Mixed_7a.branch7x7x3_1.bn.weight', 'base_model.Mixed_7a.branch7x7x3_1.bn.bias', 'base_model.Mixed_7a.branch7x7x3_1.bn.running_mean', 'base_model.Mixed_7a.branch7x7x3_1.bn.running_var', 'base_model.Mixed_7a.branch7x7x3_1.bn.num_batches_tracked', 'base_model.Mixed_7a.branch7x7x3_2.conv.weight', 'base_model.Mixed_7a.branch7x7x3_2.bn.weight', 'base_model.Mixed_7a.branch7x7x3_2.bn.bias', 'base_model.Mixed_7a.branch7x7x3_2.bn.running_mean', 'base_model.Mixed_7a.branch7x7x3_2.bn.running_var', 'base_model.Mixed_7a.branch7x7x3_2.bn.num_batches_tracked', 'base_model.Mixed_7a.branch7x7x3_3.conv.weight', 'base_model.Mixed_7a.branch7x7x3_3.bn.weight', 'base_model.Mixed_7a.branch7x7x3_3.bn.bias', 'base_model.Mixed_7a.branch7x7x3_3.bn.running_mean', 'base_model.Mixed_7a.branch7x7x3_3.bn.running_var', 'base_model.Mixed_7a.branch7x7x3_3.bn.num_batches_tracked', 'base_model.Mixed_7a.branch7x7x3_4.conv.weight', 'base_model.Mixed_7a.branch7x7x3_4.bn.weight', 'base_model.Mixed_7a.branch7x7x3_4.bn.bias', 'base_model.Mixed_7a.branch7x7x3_4.bn.running_mean', 'base_model.Mixed_7a.branch7x7x3_4.bn.running_var', 'base_model.Mixed_7a.branch7x7x3_4.bn.num_batches_tracked', 'base_model.Mixed_7b.branch1x1.conv.weight', 'base_model.Mixed_7b.branch1x1.bn.weight', 'base_model.Mixed_7b.branch1x1.bn.bias', 'base_model.Mixed_7b.branch1x1.bn.running_mean', 'base_model.Mixed_7b.branch1x1.bn.running_var', 'base_model.Mixed_7b.branch1x1.bn.num_batches_tracked', 'base_model.Mixed_7b.branch3x3_1.conv.weight', 'base_model.Mixed_7b.branch3x3_1.bn.weight', 'base_model.Mixed_7b.branch3x3_1.bn.bias', 'base_model.Mixed_7b.branch3x3_1.bn.running_mean', 'base_model.Mixed_7b.branch3x3_1.bn.running_var', 'base_model.Mixed_7b.branch3x3_1.bn.num_batches_tracked', 'base_model.Mixed_7b.branch3x3_2a.conv.weight', 'base_model.Mixed_7b.branch3x3_2a.bn.weight', 'base_model.Mixed_7b.branch3x3_2a.bn.bias', 'base_model.Mixed_7b.branch3x3_2a.bn.running_mean', 'base_model.Mixed_7b.branch3x3_2a.bn.running_var', 'base_model.Mixed_7b.branch3x3_2a.bn.num_batches_tracked', 'base_model.Mixed_7b.branch3x3_2b.conv.weight', 'base_model.Mixed_7b.branch3x3_2b.bn.weight', 'base_model.Mixed_7b.branch3x3_2b.bn.bias', 'base_model.Mixed_7b.branch3x3_2b.bn.running_mean', 'base_model.Mixed_7b.branch3x3_2b.bn.running_var', 'base_model.Mixed_7b.branch3x3_2b.bn.num_batches_tracked', 'base_model.Mixed_7b.branch3x3dbl_1.conv.weight', 'base_model.Mixed_7b.branch3x3dbl_1.bn.weight', 'base_model.Mixed_7b.branch3x3dbl_1.bn.bias', 'base_model.Mixed_7b.branch3x3dbl_1.bn.running_mean', 'base_model.Mixed_7b.branch3x3dbl_1.bn.running_var', 'base_model.Mixed_7b.branch3x3dbl_1.bn.num_batches_tracked', 'base_model.Mixed_7b.branch3x3dbl_2.conv.weight', 'base_model.Mixed_7b.branch3x3dbl_2.bn.weight', 'base_model.Mixed_7b.branch3x3dbl_2.bn.bias', 'base_model.Mixed_7b.branch3x3dbl_2.bn.running_mean', 'base_model.Mixed_7b.branch3x3dbl_2.bn.running_var', 'base_model.Mixed_7b.branch3x3dbl_2.bn.num_batches_tracked', 'base_model.Mixed_7b.branch3x3dbl_3a.conv.weight', 'base_model.Mixed_7b.branch3x3dbl_3a.bn.weight', 'base_model.Mixed_7b.branch3x3dbl_3a.bn.bias', 'base_model.Mixed_7b.branch3x3dbl_3a.bn.running_mean', 'base_model.Mixed_7b.branch3x3dbl_3a.bn.running_var', 'base_model.Mixed_7b.branch3x3dbl_3a.bn.num_batches_tracked', 'base_model.Mixed_7b.branch3x3dbl_3b.conv.weight', 'base_model.Mixed_7b.branch3x3dbl_3b.bn.weight', 'base_model.Mixed_7b.branch3x3dbl_3b.bn.bias', 'base_model.Mixed_7b.branch3x3dbl_3b.bn.running_mean', 'base_model.Mixed_7b.branch3x3dbl_3b.bn.running_var', 'base_model.Mixed_7b.branch3x3dbl_3b.bn.num_batches_tracked', 'base_model.Mixed_7b.branch_pool.conv.weight', 'base_model.Mixed_7b.branch_pool.bn.weight', 'base_model.Mixed_7b.branch_pool.bn.bias', 'base_model.Mixed_7b.branch_pool.bn.running_mean', 'base_model.Mixed_7b.branch_pool.bn.running_var', 'base_model.Mixed_7b.branch_pool.bn.num_batches_tracked', 'base_model.Mixed_7c.branch1x1.conv.weight', 'base_model.Mixed_7c.branch1x1.bn.weight', 'base_model.Mixed_7c.branch1x1.bn.bias', 'base_model.Mixed_7c.branch1x1.bn.running_mean', 'base_model.Mixed_7c.branch1x1.bn.running_var', 'base_model.Mixed_7c.branch1x1.bn.num_batches_tracked', 'base_model.Mixed_7c.branch3x3_1.conv.weight', 'base_model.Mixed_7c.branch3x3_1.bn.weight', 'base_model.Mixed_7c.branch3x3_1.bn.bias', 'base_model.Mixed_7c.branch3x3_1.bn.running_mean', 'base_model.Mixed_7c.branch3x3_1.bn.running_var', 'base_model.Mixed_7c.branch3x3_1.bn.num_batches_tracked', 'base_model.Mixed_7c.branch3x3_2a.conv.weight', 'base_model.Mixed_7c.branch3x3_2a.bn.weight', 'base_model.Mixed_7c.branch3x3_2a.bn.bias', 'base_model.Mixed_7c.branch3x3_2a.bn.running_mean', 'base_model.Mixed_7c.branch3x3_2a.bn.running_var', 'base_model.Mixed_7c.branch3x3_2a.bn.num_batches_tracked', 'base_model.Mixed_7c.branch3x3_2b.conv.weight', 'base_model.Mixed_7c.branch3x3_2b.bn.weight', 'base_model.Mixed_7c.branch3x3_2b.bn.bias', 'base_model.Mixed_7c.branch3x3_2b.bn.running_mean', 'base_model.Mixed_7c.branch3x3_2b.bn.running_var', 'base_model.Mixed_7c.branch3x3_2b.bn.num_batches_tracked', 'base_model.Mixed_7c.branch3x3dbl_1.conv.weight', 'base_model.Mixed_7c.branch3x3dbl_1.bn.weight', 'base_model.Mixed_7c.branch3x3dbl_1.bn.bias', 'base_model.Mixed_7c.branch3x3dbl_1.bn.running_mean', 'base_model.Mixed_7c.branch3x3dbl_1.bn.running_var', 'base_model.Mixed_7c.branch3x3dbl_1.bn.num_batches_tracked', 'base_model.Mixed_7c.branch3x3dbl_2.conv.weight', 'base_model.Mixed_7c.branch3x3dbl_2.bn.weight', 'base_model.Mixed_7c.branch3x3dbl_2.bn.bias', 'base_model.Mixed_7c.branch3x3dbl_2.bn.running_mean', 'base_model.Mixed_7c.branch3x3dbl_2.bn.running_var', 'base_model.Mixed_7c.branch3x3dbl_2.bn.num_batches_tracked', 'base_model.Mixed_7c.branch3x3dbl_3a.conv.weight', 'base_model.Mixed_7c.branch3x3dbl_3a.bn.weight', 'base_model.Mixed_7c.branch3x3dbl_3a.bn.bias', 'base_model.Mixed_7c.branch3x3dbl_3a.bn.running_mean', 'base_model.Mixed_7c.branch3x3dbl_3a.bn.running_var', 'base_model.Mixed_7c.branch3x3dbl_3a.bn.num_batches_tracked', 'base_model.Mixed_7c.branch3x3dbl_3b.conv.weight', 'base_model.Mixed_7c.branch3x3dbl_3b.bn.weight', 'base_model.Mixed_7c.branch3x3dbl_3b.bn.bias', 'base_model.Mixed_7c.branch3x3dbl_3b.bn.running_mean', 'base_model.Mixed_7c.branch3x3dbl_3b.bn.running_var', 'base_model.Mixed_7c.branch3x3dbl_3b.bn.num_batches_tracked', 'base_model.Mixed_7c.branch_pool.conv.weight', 'base_model.Mixed_7c.branch_pool.bn.weight', 'base_model.Mixed_7c.branch_pool.bn.bias', 'base_model.Mixed_7c.branch_pool.bn.running_mean', 'base_model.Mixed_7c.branch_pool.bn.running_var', 'base_model.Mixed_7c.branch_pool.bn.num_batches_tracked', 'base_model.fc.weight', 'base_model.fc.bias'])\n"
          ]
        }
      ],
      "source": [
        "print(checkpoint.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "1Mw6-JCOiByE",
        "outputId": "5c5b9400-b754-4880-af04-eeec83ec7318"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'InceptionV3' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-40cbba59b255>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInceptionV3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'InceptionV3' is not defined"
          ]
        }
      ],
      "source": [
        "# Extract the model's state dictionary using the correct key\n",
        "model_state_dict = checkpoint['base_model.Conv2d_1a_3x3.conv.weight']\n",
        "\n",
        "# Load the model architecture\n",
        "model = InceptionV3()\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd5VC7m5iEeA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "class InceptionV3(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InceptionV3, self).__init__()\n",
        "        self.model = models.inception_v3(pretrained=False, aux_logits=False)\n",
        "        # Modify the last fully connected layer for your specific task\n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = torch.nn.Linear(num_ftrs, 2)  # Assuming binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "4zxF5bDbiIwT",
        "outputId": "1fa73544-5a47-4eb9-ef94-f3c2e8a5b306"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Expected state_dict to be dict-like, got <class 'torch.Tensor'>.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-95effca3d31c>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInceptionV3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Set the model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2102\u001b[0m         \"\"\"\n\u001b[1;32m   2103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2104\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected state_dict to be dict-like, got {type(state_dict)}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m         \u001b[0mmissing_keys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class 'torch.Tensor'>."
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "checkpoint = torch.load('/content/drive/MyDrive/inceptionv3_model.pth')\n",
        "\n",
        "# Extract the model's state dictionary using the correct key\n",
        "model_state_dict = checkpoint['base_model.Conv2d_1a_3x3.conv.weight']\n",
        "\n",
        "# Load the model architecture\n",
        "model = InceptionV3()\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJxxK4ariNcx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras import layers, models, optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsV7KaVriZX8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def load_model():\n",
        "    # Load the entire model from the .pth file\n",
        "    model = torch.load('/content/drive/MyDrive/inceptionv3_model.pth')\n",
        "    model.eval()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLml-BHyiZUl",
        "outputId": "32855afe-6c5b-41b7-f89e-e73f81f07c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # This route will handle POST requests sent to http://yourdomain.com/predict\n",
        "    # It expects an image file to be sent as form data with key 'image'\n",
        "    # It returns a JSON response containing the prediction result\n",
        "\n",
        "    # We will implement the logic for handling image and making predictions here\n",
        "    pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMzIkK3UiZRw"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def process_image(image):\n",
        "    # Resize and normalize the image\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Assuming input size for your model\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Assuming normalization values\n",
        "    ])\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBOb2f5FiZO1"
      },
      "outputs": [],
      "source": [
        "def predict_image(image):\n",
        "    # Perform model inference\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        # Replace this with your actual prediction logic\n",
        "        # Example:\n",
        "        # prediction = output.argmax(dim=1).item()\n",
        "        # confidence = torch.nn.functional.softmax(output, dim=1)[0][prediction].item()\n",
        "        # result = 'Real' if prediction == 0 else 'Fake'\n",
        "        # confidence = round(confidence * 100, 2)\n",
        "        result = 'Real'  # Placeholder result for demonstration\n",
        "        confidence = 95.6  # Placeholder confidence for demonstration\n",
        "    return result, confidence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty2P85lniTs2"
      },
      "outputs": [],
      "source": [
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({'error': 'No image provided'}), 400\n",
        "\n",
        "    file = request.files['image']\n",
        "    image = Image.open(file.stream)\n",
        "\n",
        "    processed_image = process_image(image)\n",
        "    result, confidence = predict_image(processed_image)\n",
        "\n",
        "    return jsonify({'result': result, 'confidence': confidence})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "os8nAxMXiTpS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD2m90fbiTjq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keG4AIeUiTgY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiQvTSyBiTae"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8zIV4l7llz_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTIPxzh0lz7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QUqndRS6lz41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "omkD57inlz1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q_8ndSU_lzzW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}